## 正向渲染

每个渲染对象必须遍历每个渲染片段的每个光源。

在复杂的场景中，正向渲染浪费大量片元着色器的计算，因为片元着色器输出结果会被覆盖。

## 延迟渲染

**把计算量大的渲染推迟到后面的阶段执行。**

延迟渲染包含两个处理阶段（pass），第一个pass ： ==**geometry pass**==**，我们先渲染场景一次，之后获取对象的各种几何信息，并储存在一系列叫做==G缓冲(G-buffer)==的纹理中。几何信息比如位置向量(Position Vector)、颜色向量(Color Vector)、法向量(Normal Vector)和/或镜面值(Specular Value)。**

**G缓冲用在后面的光照计算。**

下面是一帧中G缓冲的内容：

![Untitled](渲染/渲染管线流程/延迟着色法%20Deferred%20Shading/Untitled.png)

第二个pass：==**lighting pass**==，使用G缓冲内的纹理数据渲染一个屏幕大小的方形，对使用了G缓冲内的几何信息的片段进行场景光照计算。在每个像素中我们都会对G缓冲进行迭代。我们对于渲染过程进行解耦，将它高级的片段处理挪到后期进行，而**不是直接将每个对象从顶点着色器带到片段着色器**。光照计算过程还是和以前一样，但是现在我们需要**从对应的G缓冲**而不是顶点着色器(和一些uniform变量)那里获取输入变量了。

![Untitled](渲染/渲染管线流程/延迟着色法%20Deferred%20Shading/Untitled%201.png)

这种渲染方法一个很大的好处就是能保证在G缓冲中的片段和在屏幕上呈现的像素所包含的片段信息是一样的，因为深度测试已经最终将这里的片段信息作为最顶层的片段。这样保证了对于**在光照处理阶段**中处理的**每一个像素都只处理一次**，所以我们能够省下很多无用的渲染调用。![[渲染流程图.png]]

缺点是由于G缓冲要求我们在纹理颜色缓冲中存储相对比较大的场景数据，这会**消耗比较多的显存**，尤其是类似位置向量之类的需要高精度的场景数据。 另外一个缺点就是他==**不支持混合==（Blend）**(因为我们只有最前面的片段信息)， 因此也==**不能使用MSAA**==了。

在几何处理阶段中填充G缓冲非常高效，因为我们直接储存像素位置，颜色或者是法线等对象信息到帧缓冲中，而这**几乎不会消耗处理时间**。在此基础上使用多渲染目标(Multiple Render Targets, **MRT**)技术，我们**甚至可以在一个渲染处理之内完成这所有的工作**。

现在我们已经有了一大堆的片段数据储存在G缓冲中供我们处置，我们可以选择通过一个像素一个像素地遍历各个G缓冲纹理，并将储存在它们里面的内容作为光照算法的输入，来完全计算场景最终的光照颜色。由于所有的G缓冲纹理都代表的是最终变换的片段值，我们**只需要对每一个像素执行一次昂贵的光照运算**就行了。这使得延迟光照非常高效，特别是在需要调用大量重型片段着色器的复杂场景中。

## 结合延迟渲染与正向渲染

为了克服这些缺点(特别是混合)，我们通**常分割我们的渲染器为两个部分**：一个是延迟渲染的部分，另一个是专门为了混合或者其他不适合延迟渲染管线的着色器效果而设计的的正向渲染的部分。

在延迟渲染之后开始执行正向渲染，先复制出在几何渲染阶段中储存的深度信息，并输出到默认的帧缓冲的深度缓冲，然后我们才渲染。

## **光体积(Light Volumes)**

延迟渲染一直被称赞的原因就是它能够渲染大量的光源而不消耗大量的性能。然而，延迟渲染它本身**并不能**支持非常大量的光源，因为我们仍然必须要对场景中每一个光源计算每一个片段的光照分量。真正让大量光源成为可能的是我们能够对延迟渲染管线引用的一个非常棒的优化：**光体积(Light Volumes)**

通常情况下，当我们渲染一个复杂光照场景下的片段着色器时，我们会计算场景中**每一个**光源的贡献，不管它们离这个片段有多远。**很大一部分的光源根本就不会到达这个片段**，所以为什么我们还要浪费这么多光照运算呢？

**隐藏在光体积背后的想法就是计算光源的半径，或是体积，也就是光能够到达片段的范围**。由于大部分光源都使用了某种形式的衰减(Attenuation)，我们可以用它来计算光源能够到达的最大路程，或者说是半径。我们接下来只需要对那些在一个或多个光体积内的片段进行繁重的光照运算就行了。这可以给我们省下来很可观的计算量，因为我们现在**只在需要的情况下计算光照**。

这个方法的难点基本就是找出一个光源光体积的大小，或者是半径。

使用光体积更好的方法是**渲染一个实际的球体，并根据光体积的半径缩放**。这些球的中心放置在光源的位置，由于它是根据光体积半径缩放的，这个球体正好覆盖了光的可视体积。这就是我们的技巧：我们使用大体相同的延迟片段着色器来渲染球体。因为球体产生了完全匹配于受影响像素的着色器调用，我们只渲染了受影响的像素而跳过其它的像素。

它被应用在场景中每个光源上，并且所得的片段相加混合在一起。这个结果和之前场景是一样的，但这一次只渲染对于光源相关的片段。它有效地**减少**了从`nr_objects * nr_lights`到`nr_objects + nr_lights`的计算量，这使得多光源场景的渲染变得无比高效。这正是为什么延迟渲染非常适合渲染很大数量光源。

然而这个方法仍然有一个问题：面剔除(Face Culling)需要被启用(否则我们会渲染一个光效果两次)，并且在它启用的时候用户可能进入一个光源的光体积，然而这样之后这个体积就不再被渲染了(由于背面剔除)，这会使得光源的影响消失。这个问题可以通过一个模板缓冲技巧来解决。

渲染光体积确实会带来沉重的性能负担，虽然它通常比普通的延迟渲染更快，这仍然不是最好的优化。另外两个基于延迟渲染的更流行(并且更高效)的拓展叫做**延迟光照(Deferred Lighting)**和**切片式延迟着色法(Tile-based Deferred Shading)**。这些方法会很大程度上提高大量光源渲染的效率，并且也能允许一个相对高效的多重采样抗锯齿(MSAA)。

## 延迟渲染 vs 正向渲染

仅仅是延迟着色法它本身(没有光体积)已经是一个很大的优化了，每**个像素仅仅运行一个单独的片段着色器**，然而对于正向渲染，我们通常**会对一个像素运行多次片段着色器**。当然，延迟渲染确实带来一些缺点：大内存开销，没有MSAA和混合(仍需要正向渲染的配合)。

当你有一个很小的场景并且没有很多的光源时候，延迟渲染并不一定会更快一点，甚至有些时候由于开销超过了它的优点还会更慢。然而在一个更复杂的场景中，延迟渲染会快速变成一个重要的优化，特别是有了更先进的优化拓展的时候。

最后我仍然想指出，基本上所有能通过正向渲染完成的效果能够同样在延迟渲染场景中实现，这通常需要一些小的翻译步骤。举个例子，如果我们想要在延迟渲染器中使用法线贴图(Normal Mapping)，我们需要改变几何渲染阶段（the geometry pass）着色器来输出一个世界空间法线(World-space Normal)，它从法线贴图中提取出来(使用一个TBN矩阵)而不是表面法线，光照渲染阶段中的光照运算一点都不需要变。如果你想要让视差贴图工作，首先你需要在采样一个物体的漫反射，镜面，和法线纹理之前首先置换几何渲染阶段中的纹理坐标。一旦你了解了延迟渲染背后的理念，变得有创造力并不是什么难事。